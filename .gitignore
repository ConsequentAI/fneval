# save your api keys to this file, for convenient . ./api_keys.sh export
api_keys.sh

# source static dataset
MATH.tar
MATH/

# untarred monthly snapshots
Dec-2023/
Nov-2023/
Oct-2023/

# caches (the saved snapshots can be checked in as .tar.gz, but no need for the untarred dirs)
api_query_cache/Anthropic_Eval_claude-2.1/
api_query_cache/Mistral_Eval_mistral-medium/
api_query_cache/OAI_Eval_davinci/
api_query_cache/OAI_Eval_gpt-3.5-turbo/
api_query_cache/OAI_Eval_gpt-4/
api_query_cache/Together_Eval_EleutherAI_llemma_7b/
api_query_cache/Together_Eval_WizardLM_WizardCoder-Python-34B-V1.0/
api_query_cache/Together_Eval_mistralai_Mixtral-8x7B-Instruct-v0.1/
api_query_cache/Together_Eval_mistralai_Mixtral-8x7B-v0.1/
api_query_cache/Together_Eval_togethercomputer_Qwen-7B/
api_query_cache/Together_Eval_togethercomputer_StripedHyena-Hessian-7B/
api_query_cache/Together_Eval_togethercomputer_StripedHyena-Nous-7B/
api_query_cache/Together_Eval_togethercomputer_llama-2-70b/
api_query_cache/Together_Eval_zero-one-ai_Yi-34B-Chat/
api_query_cache/Together_Eval_zero-one-ai_Yi-34B/

# output of individual evals, intermediate from eval/measure_math.py
intermediate

# individual test results from model evals; output of evaluate.py
evaluated_models.json.pickle

# output of summarize_evals.py
evaluated_models.stat*

# mac
.DS_Store
